{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ScatteringGCN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyONl+I//88THTa+1PuHueh9"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBaBUmCRcajv"
      },
      "source": [
        "# SCATTERING GCN: Overcoming Oversmoothness in Graph Convolutional Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fpdtgnr7nvar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7be1f030-0ccb-41e2-8652-c2fe49705ead"
      },
      "source": [
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.9.0+cu111.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-1.9.0+cu111.html\n",
        "!pip install torch-geometric"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-1.9.0+cu111.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.9.0%2Bcu111/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (10.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4 MB 8.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.9.0+cu111.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.9.0%2Bcu111/torch_sparse-0.6.12-cp37-cp37m-linux_x86_64.whl (3.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7 MB 7.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.12\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.0.3.tar.gz (370 kB)\n",
            "\u001b[K     |████████████████████████████████| 370 kB 10.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.62.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.6.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n",
            "Collecting rdflib\n",
            "  Downloading rdflib-6.1.1-py3-none-any.whl (482 kB)\n",
            "\u001b[K     |████████████████████████████████| 482 kB 58.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.7)\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.13)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (57.4.0)\n",
            "Collecting isodate\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 722 kB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (4.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric) (3.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.3-py3-none-any.whl size=581968 sha256=97de7bf26f526151b77094bbdc12f3c5a3896a1e0a4e22bb4a6cdd436be7b6d3\n",
            "  Stored in directory: /root/.cache/pip/wheels/c3/2a/58/87ce0508964d4def1aafb92750c4f3ac77038efd1b9a89dcf5\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: isodate, yacs, rdflib, torch-geometric\n",
            "Successfully installed isodate-0.6.1 rdflib-6.1.1 torch-geometric-2.0.3 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNVunctHn_Zf"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parameter import Parameter\n",
        "import torch.nn as nn\n",
        "from torch.nn.modules.module import Module\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import MultiStepLR,StepLR\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle as pkl\n",
        "import sys\n",
        "import networkx as nx\n",
        "import scipy.sparse as sp\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hre3f387otE7",
        "outputId": "0580b4e9-9dbc-4499-8693-60eed45ece68"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGjJCnPwcpwq"
      },
      "source": [
        "# Utils functions: normalization, preprocessing and accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeM-VWpbq-oD"
      },
      "source": [
        "def normalize_adjacency_matrix(A, I):\n",
        "  \"\"\"\n",
        "  Creating a normalized adjacency matrix with self loops.\n",
        "  :param A: Sparse adjacency matrix.\n",
        "  :param I: Identity matrix.\n",
        "  :return A_tile_hat: Normalized adjacency matrix.\"\"\"\n",
        "  \n",
        "  A_tilde = A + I\n",
        "  degrees = A_tilde.sum(axis=0)[0].tolist()\n",
        "  D = sp.diags(degrees, [0])\n",
        "  D = D.power(-0.5)\n",
        "  A_tilde_hat = D.dot(A_tilde).dot(D)\n",
        "  return A_tilde_hat\n",
        "\n",
        "def normalize(mx):\n",
        "  \"\"\"Row-normalize sparse matrix ---> Node features\"\"\"\n",
        "  rowsum = np.array(mx.sum(1))\n",
        "  r_inv = np.power(rowsum, -1).flatten()\n",
        "  r_inv[np.isinf(r_inv)] = 0.\n",
        "  r_mat_inv = sp.diags(r_inv)\n",
        "  mx = r_mat_inv.dot(mx)\n",
        "  return mx\n",
        "\n",
        "def normalizemx(mx):\n",
        "  \"\"\"Normalization for Scattering GCN\"\"\"\n",
        "  degrees = mx.sum(axis=0)[0].tolist()\n",
        "  #    print(degrees)\n",
        "  D = sp.diags(degrees, [0])\n",
        "  D = D.power(-1)\n",
        "  mx = mx.dot(D)\n",
        "  return mx\n",
        "\n",
        "\n",
        "def scattering1st(spmx,order):\n",
        "\n",
        "  I_n = sp.eye(spmx.shape[0])\n",
        "  adj_sct = 0.5*(spmx+I_n) # P = 1/2 * (I + WD^-1)\n",
        "  adj_power = adj_sct\n",
        "  adj_power = sparse_mx_to_torch_sparse_tensor(adj_power).cuda()\n",
        "  adj_sct = sparse_mx_to_torch_sparse_tensor(adj_sct).cuda()\n",
        "  I_n = sparse_mx_to_torch_sparse_tensor(I_n)\n",
        "  if order>1:\n",
        "    for i in range(order-1):\n",
        "      # Generating P^(2^(k-1))\n",
        "      adj_power = torch.spmm(adj_power,adj_sct.to_dense())\n",
        "      print('Generating SCT')\n",
        "    # Generating. final scattering of order K -> (I - P^(2^(k-1))) * P^(2^(k-1))\n",
        "    adj_int = torch.spmm((adj_power-I_n.cuda()),adj_power)\n",
        "  else:\n",
        "    # Generating. final scattering of order K -> (I - P^(2^(k-1))) * P^(2^(k-1))\n",
        "    adj_int = torch.spmm((adj_power-I_n.cuda()),adj_power.to_dense())\n",
        "  return adj_int\n",
        "\n",
        "\n",
        "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
        "  \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
        "  sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
        "  indices = torch.from_numpy(np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
        "  values = torch.from_numpy(sparse_mx.data)\n",
        "  shape = torch.Size(sparse_mx.shape)\n",
        "  return torch.sparse.FloatTensor(indices, values, shape)\n",
        "\n",
        "\n",
        "def parse_index_file(filename):\n",
        "  #Parse index file.\n",
        "  index = []\n",
        "  for line in open(filename):\n",
        "      index.append(int(line.strip()))\n",
        "  return index\n",
        "\n",
        "def accuracy(output, labels):\n",
        "  preds = output.max(1)[1].type_as(labels)\n",
        "  correct = preds.eq(labels).double()\n",
        "  correct = correct.sum()\n",
        "  return correct / len(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxQBxTmucyB4"
      },
      "source": [
        "# Preprocessing: Importing datasets\n",
        "\n",
        "Importing the datasets, split into training, validation and testing, getting the adjacency matrix, the scattering matrices, features matrix, index of nodes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSqg-oFuoApE"
      },
      "source": [
        "def load_citation(dataset_str=\"pubmed\", normalization=\"AugNormAdj\", cuda=True):\n",
        "  \"\"\"  \n",
        "  Load Citation Networks Datasets.\n",
        "  \"\"\"\n",
        "  names = ['x', 'y', 'tx', 'ty', 'allx', 'ally', 'graph']\n",
        "  objects = []\n",
        "  for i in range(len(names)):\n",
        "    with open(\"/content/drive/MyDrive/THESIS/Databases/data/ind.{}.{}\".format(dataset_str.lower(), names[i]), 'rb') as f:\n",
        "      if sys.version_info > (3, 0):\n",
        "          objects.append(pkl.load(f, encoding='latin1'))\n",
        "      else:\n",
        "          objects.append(pkl.load(f))\n",
        "\n",
        "  x, y, tx, ty, allx, ally, graph = tuple(objects)\n",
        "  test_idx_reorder = parse_index_file(\"/content/drive/MyDrive/THESIS/Databases/data/ind.{}.test.index\".format(dataset_str))\n",
        "  test_idx_range = np.sort(test_idx_reorder)\n",
        "\n",
        "  if dataset_str == 'citeseer':\n",
        "    # Fix citeseer dataset (there are some isolated nodes in the graph)\n",
        "    # Find isolated nodes, add them as zero-vecs into the right position\n",
        "    test_idx_range_full = range(min(test_idx_reorder), max(test_idx_reorder)+1)\n",
        "    tx_extended = sp.lil_matrix((len(test_idx_range_full), x.shape[1]))\n",
        "    tx_extended[test_idx_range-min(test_idx_range), :] = tx\n",
        "    tx = tx_extended\n",
        "    ty_extended = np.zeros((len(test_idx_range_full), y.shape[1]))\n",
        "    ty_extended[test_idx_range-min(test_idx_range), :] = ty\n",
        "    ty = ty_extended\n",
        "\n",
        "  features = sp.vstack((allx, tx)).tolil()\n",
        "  features[test_idx_reorder, :] = features[test_idx_range, :]\n",
        "  adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph))\n",
        "  adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
        "  labels = np.vstack((ally, ty))\n",
        "  labels[test_idx_reorder, :] = labels[test_idx_range, :]\n",
        "\n",
        "\n",
        "  idx_test = test_idx_range.tolist()\n",
        "  idx_train = range(len(y))\n",
        "  idx_val = range(len(y), len(y)+500)\n",
        "\n",
        "  #   take from https://github.com/tkipf/pygcn/blob/master/pygcn/utils.py\n",
        "  #    idx_train = range(140)\n",
        "  #    idx_val = range(200, 500)\n",
        "  #    idx_test = range(500, 1500)\n",
        "\n",
        "\n",
        "  labels = torch.LongTensor(labels)\n",
        "  labels = torch.max(labels, dim=1)[1]\n",
        "  idx_train = torch.LongTensor(idx_train)\n",
        "  idx_val = torch.LongTensor(idx_val)\n",
        "  idx_test = torch.LongTensor(idx_test)\n",
        "\n",
        "  features = normalize(features)\n",
        "  A_tilde = normalize_adjacency_matrix(adj,sp.eye(adj.shape[0]))\n",
        "  adj = normalizemx(adj)\n",
        "  features = torch.FloatTensor(np.array(features.todense()))\n",
        "  print('Loading')\n",
        "  adj_sct1 = scattering1st(adj,1) ## psi_1 = P(I-P)\n",
        "  adj_sct2 = scattering1st(adj,2) # psi_2 = P^2(I-P^2)\n",
        "  adj_sct4 = scattering1st(adj,4) # psi_3 = P^4(I-P^4)\n",
        "  adj = sparse_mx_to_torch_sparse_tensor(adj)\n",
        "  A_tilde = sparse_mx_to_torch_sparse_tensor(A_tilde)\n",
        "  return adj,A_tilde,adj_sct1,adj_sct2,adj_sct4,features, labels, idx_train, idx_val, idx_test\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "xSQpsNIHpNIR",
        "outputId": "d0f50ac6-79f9-4013-b009-f220b49b1963"
      },
      "source": [
        "adj,A_tilde,adj_sct1,adj_sct2,adj_sct4,features, labels, idx_train, idx_val, idx_test = load_citation()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnpicklingError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-24120b8b4709>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0madj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA_tilde\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0madj_sct1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0madj_sct2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0madj_sct4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_citation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-a40c0d32d45e>\u001b[0m in \u001b[0;36mload_citation\u001b[0;34m(dataset_str, normalization, cuda)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/THESIS/Databases/data/ind.{}.{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m           \u001b[0mobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m           \u001b[0mobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnpicklingError\u001b[0m: pickle data was truncated"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxLDPDUHdIpH"
      },
      "source": [
        "# MODELS\n",
        "\n",
        "First the convolutional structure is defined to finally being called in a nn Module. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vouttenVJG0U"
      },
      "source": [
        "class GC_withres(Module):\n",
        "  \"\"\"\n",
        "  res conv\n",
        "  \"\"\"\n",
        "  def __init__(self, in_features, out_features,smooth,bias=True):\n",
        "    super(GC_withres, self).__init__()\n",
        "    self.in_features = in_features\n",
        "    self.out_features = out_features\n",
        "    self.smooth = smooth\n",
        "    self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
        "    if bias:\n",
        "        self.bias = Parameter(torch.FloatTensor(out_features))\n",
        "    else:\n",
        "        self.register_parameter('bias', None)\n",
        "    self.reset_parameters()\n",
        "  def reset_parameters(self):\n",
        "    stdv = 1. / math.sqrt(self.weight.size(1))\n",
        "    self.weight.data.uniform_(-stdv, stdv)\n",
        "    if self.bias is not None:\n",
        "        self.bias.data.uniform_(-stdv, stdv)\n",
        "  def forward(self, input, adj):\n",
        "    print('adj', adj.shape)\n",
        "    print('input', input.shape)\n",
        "    # adj is extracted from the graph structure\n",
        "    support = torch.mm(input, self.weight)\n",
        "    I_n = sp.eye(adj.shape[0])\n",
        "    I_n = sparse_mx_to_torch_sparse_tensor(I_n).cuda()\n",
        "    output = torch.spmm((I_n+self.smooth*adj)/(1+self.smooth), support)\n",
        "    if self.bias is not None:\n",
        "        return output + self.bias\n",
        "    else:\n",
        "        return output\n",
        "\n",
        "\n",
        "class NGCN(Module):\n",
        "  \"\"\"\n",
        "  Bandpass model, consider 3 Lap matrix\n",
        "  \"\"\"\n",
        "  def __init__(self, in_features,med_f0,med_f1,med_f2,med_f3,med_f4,bias=True):\n",
        "    super(NGCN, self).__init__()\n",
        "    self.in_features = in_features\n",
        "    self.med_f0 = med_f0\n",
        "    self.med_f1 = med_f1\n",
        "    self.med_f2 = med_f2\n",
        "    self.med_f3 = med_f3\n",
        "    self.med_f4 = med_f4\n",
        "\n",
        "    self.weight0 = Parameter(torch.FloatTensor(in_features, med_f0))\n",
        "    self.weight1 = Parameter(torch.FloatTensor(in_features, med_f1))\n",
        "    self.weight2 = Parameter(torch.FloatTensor(in_features, med_f2))\n",
        "    self.weight3 = Parameter(torch.FloatTensor(in_features, med_f3))\n",
        "    self.weight4 = Parameter(torch.FloatTensor(in_features, med_f4))\n",
        "\n",
        "\n",
        "    #self.weight = Parameter(torch.FloatTensor((med_f0+med_f1+med_f2), out_features))\n",
        "\n",
        "    if bias:\n",
        "        self.bias1 = Parameter(torch.FloatTensor(med_f1))\n",
        "        self.bias0 = Parameter(torch.FloatTensor(med_f0))\n",
        "        self.bias2 = Parameter(torch.FloatTensor(med_f2))\n",
        "        self.bias3 = Parameter(torch.FloatTensor(med_f3))\n",
        "        self.bias4 = Parameter(torch.FloatTensor(med_f4))\n",
        "\n",
        "    else:\n",
        "        self.register_parameter('bias', None)\n",
        "    self.reset_parameters()\n",
        "  def reset_parameters(self):\n",
        "    stdv0 = 1. / math.sqrt(self.weight0.size(1))\n",
        "    stdv1 = 1. / math.sqrt(self.weight1.size(1))\n",
        "    stdv2 = 1. / math.sqrt(self.weight2.size(1))\n",
        "\n",
        "    stdv3 = 1. / math.sqrt(self.weight3.size(1))\n",
        "    stdv4 = 1. / math.sqrt(self.weight4.size(1))\n",
        "    torch.nn.init.xavier_uniform(self.weight0)\n",
        "    torch.nn.init.xavier_uniform(self.weight2)\n",
        "    torch.nn.init.xavier_uniform(self.weight1)\n",
        "    torch.nn.init.xavier_uniform(self.weight3)\n",
        "    torch.nn.init.xavier_uniform(self.weight4)\n",
        "    if self.bias0 is not None:\n",
        "        self.bias1.data.uniform_(-stdv1, stdv1)\n",
        "        self.bias0.data.uniform_(-stdv0, stdv0)\n",
        "        self.bias2.data.uniform_(-stdv2, stdv2)\n",
        "\n",
        "        self.bias3.data.uniform_(-stdv3, stdv3)\n",
        "        self.bias4.data.uniform_(-stdv4, stdv4)\n",
        "\n",
        "  def forward(self, input, adj,A_tilde,s1_sct,s2_sct,s3_sct,adj_sct_o1,adj_sct_o2):\n",
        "    # adj is extracted from the graph structure\n",
        "    # adj_sct_o1,adj_sct_o2: two scatterng matrix index of different order\n",
        "    # e.g. adj_sct_o1 = [1,1]--> denotes 1st order, 1 index\n",
        "    # e.g. adj_sct_o1 = [2,1]--> denotes 2nd order\n",
        "    # 1_sct,2_sct,3_sct: three first order matrix\n",
        "    support0 = torch.mm(input, self.weight0)\n",
        "    output0 = torch.spmm(A_tilde, support0) + self.bias0\n",
        "    support1 = torch.mm(input, self.weight1)\n",
        "    output1 = torch.spmm(A_tilde, support1)\n",
        "    output1 = torch.spmm(A_tilde, output1)+ self.bias1\n",
        "\n",
        "    support2 = torch.mm(input, self.weight2)\n",
        "    output2 = torch.spmm(A_tilde, support2)\n",
        "    output2 = torch.spmm(A_tilde, output2)\n",
        "    output2 = torch.spmm(A_tilde, output2)+ self.bias2\n",
        "    support3 = torch.mm(input, self.weight3) \n",
        "    if adj_sct_o1[0] == 1:\n",
        "        if adj_sct_o1[1] == 1:\n",
        "            output3 = torch.spmm(s1_sct.cuda(), support3)+ self.bias3\n",
        "        elif adj_sct_o1[1] == 2:\n",
        "            output3 = torch.spmm(s2_sct.cuda(), support3)+ self.bias3\n",
        "        elif adj_sct_o1[1] == 3:\n",
        "            output3 = torch.spmm(s3_sct.cuda(), support3)+ self.bias3\n",
        "        else:\n",
        "            print('Please type in the right index!')\n",
        "\n",
        "    elif adj_sct_o1[0] == 2:\n",
        "        # second order scatt\n",
        "        # adj_sct_o1[1] == 1----> psi_2|psi_1 x |\n",
        "        # adj_sct_o1[1] == 2----> psi_3|psi_1 x |\n",
        "        # adj_sct_o1[1] == 3----> psi_3|psi_2 x |\n",
        "        if adj_sct_o1[1] == 1:\n",
        "            output3 = torch.spmm(s2_sct.cuda(),torch.FloatTensor.abs(torch.spmm(s1_sct.cuda(), support3)))+ self.bias3\n",
        "        elif adj_sct_o1[1] == 2:\n",
        "            output3 = torch.spmm(s3_sct.cuda(),torch.FloatTensor.abs(torch.spmm(s1_sct.cuda(), support3)))+ self.bias3\n",
        "        elif adj_sct_o1[1] == 3:\n",
        "            output3 = torch.spmm(s3_sct.cuda(),torch.FloatTensor.abs(torch.spmm(s2_sct.cuda(), support3)))+ self.bias3\n",
        "        else:\n",
        "            print('Please type in the right index!')\n",
        "    else:\n",
        "        print('Please type in the right index!')\n",
        "\n",
        "\n",
        "    support4 = torch.mm(input, self.weight4)\n",
        "    if adj_sct_o2[0] == 1:\n",
        "        if adj_sct_o2[1] == 1:\n",
        "            output4 = torch.spmm(s1_sct.cuda(), support4)+ self.bias4\n",
        "        elif adj_sct_o2[1] == 2:\n",
        "            output4 = torch.spmm(s2_sct.cuda(), support4)+ self.bias4\n",
        "        elif adj_sct_o2[1] == 3:\n",
        "            output4 = torch.spmm(s3_sct.cuda(), support4)+ self.bias4\n",
        "        else:\n",
        "            print('Please type in the right index!')\n",
        "\n",
        "    elif adj_sct_o2[0] == 2:\n",
        "        # second order scatt\n",
        "        # adj_sct_o1[1] == 1----> psi_2|psi_1 x |\n",
        "        # adj_sct_o1[1] == 2----> psi_3|psi_1 x |\n",
        "        # adj_sct_o1[1] == 3----> psi_3|psi_2 x |\n",
        "        if adj_sct_o2[1] == 1:\n",
        "            output4 = torch.spmm(s2_sct.cuda(),torch.FloatTensor.abs(torch.spmm(s1_sct.cuda(), support4)))+ self.bias4\n",
        "        elif adj_sct_o2[1] == 2:\n",
        "            output4 = torch.spmm(s3_sct.cuda(),torch.FloatTensor.abs(torch.spmm(s1_sct.cuda(), support4)))+ self.bias4\n",
        "        elif adj_sct_o2[1] == 3:\n",
        "            output4 = torch.spmm(s3_sct.cuda(),torch.FloatTensor.abs(torch.spmm(s2_sct.cuda(), support4)))+ self.bias4\n",
        "        else:\n",
        "            print('Please type in the right index!')\n",
        "    else:\n",
        "        print('Please type in the right index!')\n",
        "\n",
        "    print('output0', output0.shape)\n",
        "    print('output1', output1.shape)\n",
        "    print('output2', output2.shape)\n",
        "    print('output3', output3.shape)\n",
        "    print('output4', output4.shape)\n",
        "    support_3hop = torch.cat((output0,output1,output2,output3,output4), 1)\n",
        "    output_3hop = support_3hop\n",
        "    if self.bias0 is not None:\n",
        "        print('output', output_3hop.shape)\n",
        "        return output_3hop  \n",
        "        #return output_3hop\n",
        "    else:\n",
        "        print('output', output_3hop.shape)\n",
        "        return output_3hop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1YqPqgN2WMx"
      },
      "source": [
        "class GCN(nn.Module):\n",
        "  def __init__(self, nfeat, para3,para4, nclass, dropout,smoo):\n",
        "    super(GCN, self).__init__()\n",
        "\n",
        "    self.gc1 = NGCN(nfeat,med_f0=10,med_f1=10,med_f2=10,med_f3=para3,med_f4=para4)\n",
        "    # self.gc1 = NGCN(nfeat,med_f0=28,med_f1=1,med_f2=1,med_f3=para3,med_f4=para4)\n",
        "    # self.gc2 = NGCN(30+para3+para4,med_f0=28,med_f1=1,med_f2=1,med_f3=para3,med_f4=para4)\n",
        "    self.gc11 = GC_withres(30+para3+para4, nclass,smooth=smoo)\n",
        "    self.dropout = dropout\n",
        "\n",
        "  def forward(self, x,adj, A_tilde,s1_sct,s2_sct,s3_sct,\\\n",
        "          sct_index1,\\\n",
        "          sct_index2):\n",
        "    x = torch.FloatTensor.abs_(self.gc1(x,adj,A_tilde,\\\n",
        "            s1_sct,s2_sct,s3_sct,\\\n",
        "            adj_sct_o1 = sct_index1,\\\n",
        "            adj_sct_o2 = sct_index2))**4\n",
        "    x = F.dropout(x, self.dropout, training=self.training)\n",
        "    x = self.gc11(x, adj)\n",
        "    return F.log_softmax(x, dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nh_t-pE4dUnI"
      },
      "source": [
        "# Execution of the overall model\n",
        "\n",
        "Hyperparameter definition, model instatiated, and training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_17zsYjUKfEP",
        "outputId": "3cc5f26c-36f3-4d28-84be-6bdb43d44f29"
      },
      "source": [
        "torch.manual_seed(42)\n",
        "hidden1 = 16\n",
        "hidden2 = 51\n",
        "epochs = 2\n",
        "lr = 0.005\n",
        "smoot= 0.5\n",
        "dropouts = 0.92\n",
        "order_1 = 1\n",
        "sct_inx1 = 1\n",
        "order_2 = 1\n",
        "sct_inx2 = 3\n",
        "weight_decays = 0.05\n",
        "fastmode = False\n",
        "cuda = torch.cuda.is_available()\n",
        "\n",
        "model = GCN(nfeat=features.shape[1],para3=hidden1,para4=hidden2,nclass=labels.max().item() + 1,dropout=dropouts,smoo=smoot)\n",
        "\n",
        "if cuda:\n",
        "    model = model.cuda()\n",
        "    features = features.cuda()\n",
        "    A_tilde = A_tilde.cuda()\n",
        "    adj = adj.cuda()\n",
        "    labels = labels.cuda()\n",
        "    idx_train = idx_train.cuda()\n",
        "    idx_val = idx_val.cuda()\n",
        "    idx_test = idx_test.cuda()\n",
        "\n",
        "    \n",
        "optimizer = optim.Adam(model.parameters(),lr=lr)\n",
        "scheduler = StepLR(optimizer, step_size=50, gamma=0.9)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:74: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:75: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:76: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:77: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:78: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNFlZ62nO16u",
        "outputId": "a0b9791e-3bca-42f5-9d08-c2608ce24849"
      },
      "source": [
        "acc_val_list = []\n",
        "def train(epoch):\n",
        "\n",
        "\n",
        "  global valid_error\n",
        "  t = time.time()\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "  output = model(features,adj,A_tilde,adj_sct1,adj_sct2,adj_sct4,[order_1,sct_inx1],[order_2,sct_inx2])\n",
        "  loss_train = F.nll_loss(output[idx_train], labels[idx_train])\n",
        "\n",
        "  regularization_loss = 0\n",
        "  for param in model.parameters():\n",
        "      regularization_loss = torch.sum(torch.abs(param))\n",
        "\n",
        "  loss_train = regularization_loss*weight_decays+loss_train\n",
        "  acc_train = accuracy(output[idx_train], labels[idx_train])\n",
        "  loss_train.backward()\n",
        "  optimizer.step()\n",
        "  if not fastmode:\n",
        "      # Evaluate validation set performance separately,\n",
        "      # deactivates dropout during validation run.\n",
        "      model.eval()\n",
        "      output = model(features,adj,A_tilde,adj_sct1,adj_sct2,adj_sct4,[order_1,sct_inx1],[order_2,sct_inx2])\n",
        "  loss_val = F.nll_loss(output[idx_val], labels[idx_val])\n",
        "  acc_val = accuracy(output[idx_val], labels[idx_val])\n",
        "  \"\"\"print('Epoch: {:04d}'.format(epoch+1),\n",
        "          'hidden1: {:04d}'.format(hidden1),\n",
        "          'hidden2: {:04d}'.format(hidden2),\n",
        "        'loss_train: {:.4f}'.format(loss_train.item()),\n",
        "        'acc_train: {:.4f}'.format(acc_train.item()),\n",
        "        'loss_val: {:.4f}'.format(loss_val.item()),\n",
        "        'acc_val: {:.4f}'.format(acc_val.item()),\n",
        "        'time: {:.4f}s'.format(time.time() - t))\"\"\"\n",
        "  acc_val_list.append(acc_val.item())\n",
        "  valid_error = 1.0 - acc_val.item()\n",
        "\n",
        "\n",
        "def test():\n",
        "  model.eval()\n",
        "  output = model(features,adj,A_tilde,adj_sct1,adj_sct2,adj_sct4,[order_1,sct_inx1],[order_2,sct_inx2])\n",
        "  loss_test = F.nll_loss(output[idx_test], labels[idx_test])\n",
        "  acc_test = accuracy(output[idx_test], labels[idx_test])\n",
        "  \"\"\"print(\"Test set results:\",\n",
        "        \"loss= {:.4f}\".format(loss_test.item()),\n",
        "        \"accuracy= {:.4f}\".format(acc_test.item()))\n",
        "  acc_val_list.append(acc_test.item())\n",
        "  \"\"\"\n",
        "# Train model\n",
        "t_total = time.time()\n",
        "#from pytorchtools import EarlyStopping\n",
        "\n",
        "#patience = patience\n",
        "#early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  train(epoch)\n",
        "  scheduler.step()\n",
        "  #    print(valid_error)\n",
        "  #    early_stopping(valid_error, model)\n",
        "  #    if early_stopping.early_stop:\n",
        "  #        print(\"Early stopping\")\n",
        "  #        break\n",
        "print(\"Optimization Finished!\")\n",
        "print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
        "\n",
        "# Testing\n",
        "test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output0 torch.Size([2708, 10])\n",
            "output1 torch.Size([2708, 10])\n",
            "output2 torch.Size([2708, 10])\n",
            "output3 torch.Size([2708, 16])\n",
            "output4 torch.Size([2708, 51])\n",
            "output torch.Size([2708, 97])\n",
            "adj torch.Size([2708, 2708])\n",
            "input torch.Size([2708, 97])\n",
            "output0 torch.Size([2708, 10])\n",
            "output1 torch.Size([2708, 10])\n",
            "output2 torch.Size([2708, 10])\n",
            "output3 torch.Size([2708, 16])\n",
            "output4 torch.Size([2708, 51])\n",
            "output torch.Size([2708, 97])\n",
            "adj torch.Size([2708, 2708])\n",
            "input torch.Size([2708, 97])\n",
            "output0 torch.Size([2708, 10])\n",
            "output1 torch.Size([2708, 10])\n",
            "output2 torch.Size([2708, 10])\n",
            "output3 torch.Size([2708, 16])\n",
            "output4 torch.Size([2708, 51])\n",
            "output torch.Size([2708, 97])\n",
            "adj torch.Size([2708, 2708])\n",
            "input torch.Size([2708, 97])\n",
            "output0 torch.Size([2708, 10])\n",
            "output1 torch.Size([2708, 10])\n",
            "output2 torch.Size([2708, 10])\n",
            "output3 torch.Size([2708, 16])\n",
            "output4 torch.Size([2708, 51])\n",
            "output torch.Size([2708, 97])\n",
            "adj torch.Size([2708, 2708])\n",
            "input torch.Size([2708, 97])\n",
            "Optimization Finished!\n",
            "Total time elapsed: 0.0989s\n",
            "output0 torch.Size([2708, 10])\n",
            "output1 torch.Size([2708, 10])\n",
            "output2 torch.Size([2708, 10])\n",
            "output3 torch.Size([2708, 16])\n",
            "output4 torch.Size([2708, 51])\n",
            "output torch.Size([2708, 97])\n",
            "adj torch.Size([2708, 2708])\n",
            "input torch.Size([2708, 97])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE8DlR13efKV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}