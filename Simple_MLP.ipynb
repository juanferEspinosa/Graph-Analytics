{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple MLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO2arFRBjpLvjaQU0WecpdM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanferEspinosa/Graph-Analytics/blob/main/Simple_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riczb-6JTC_V",
        "outputId": "648b36b7-b3e3-4686-c8ff-118821818111"
      },
      "source": [
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.9.0+cu111.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-1.9.0+cu111.html\n",
        "!pip install torch-geometric"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-1.9.0+cu111.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.7/dist-packages (2.0.9)\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.9.0+cu111.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.7/dist-packages (0.6.12)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.7/dist-packages (2.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.13)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n",
            "Requirement already satisfied: yacs in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.1.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: rdflib in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (6.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.62.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.6.3)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: isodate in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (0.6.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (57.4.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gr5fAtfJqbik"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PiYog6TTF4d"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parameter import Parameter\n",
        "import torch.nn as nn\n",
        "from torch.nn.modules.module import Module\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import MultiStepLR,StepLR\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle as pkl\n",
        "import sys\n",
        "import networkx as nx\n",
        "import scipy.sparse as sp\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgL739ywTG71",
        "outputId": "ac3b8a40-3afe-4582-a3b6-141b49b53282"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPYsQ3o7TQJh"
      },
      "source": [
        "# Utils functions: visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzPRSMIETIus"
      },
      "source": [
        "def visualize(h, color, epoch=None, loss=None):\n",
        "    plt.figure(figsize=(7,7))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "    if torch.is_tensor(h):\n",
        "        h = h.detach().cpu().numpy()\n",
        "        plt.scatter(h[:, 0], h[:, 1], s=140, c=color, cmap=\"Set2\")\n",
        "        if epoch is not None and loss is not None:\n",
        "            plt.xlabel(f'Epoch: {epoch}, Loss: {loss.item():.4f}', fontsize=16)\n",
        "    else:\n",
        "        nx.draw_networkx(h, pos=nx.spring_layout(h, seed=42), with_labels=False,\n",
        "                         node_color=color, cmap=\"Set2\")\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0xWNncATUnU"
      },
      "source": [
        "# Preprocessing: Importing datasets\n",
        "\n",
        "Importing the datasets, split into training, validation and testing, normalizing it, getting the adjacency matrix, the scattering matrices, features matrix, index of nodes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTtpF3qdTPgu"
      },
      "source": [
        "def normalize_adjacency_matrix(A, I):\n",
        "  \"\"\"\n",
        "  Creating a normalized adjacency matrix with self loops.\n",
        "  :param A: Sparse adjacency matrix.\n",
        "  :param I: Identity matrix.\n",
        "  :return A_tile_hat: Normalized adjacency matrix.\"\"\"\n",
        "  \n",
        "  A_tilde = I\n",
        "  degrees = A_tilde.sum(axis=0)[0].tolist()\n",
        "  D = sp.diags(degrees, [0])\n",
        "  D = D.power(-0.5)\n",
        "  A_tilde_hat = D.dot(A_tilde).dot(D)\n",
        "  return A_tilde_hat\n",
        "\n",
        "def normalize(mx):\n",
        "  \"\"\"Row-normalize sparse matrix ---> Node features\"\"\"\n",
        "  rowsum = np.array(mx.sum(1))\n",
        "  r_inv = np.power(rowsum, -1).flatten()\n",
        "  r_inv[np.isinf(r_inv)] = 0.\n",
        "  r_mat_inv = sp.diags(r_inv)\n",
        "  mx = r_mat_inv.dot(mx)\n",
        "  return mx\n",
        "\n",
        "def normalizemx(mx):\n",
        "  \"\"\"Normalization for Scattering GCN\"\"\"\n",
        "  degrees = mx.sum(axis=0)[0].tolist()\n",
        "  #    print(degrees)\n",
        "  D = sp.diags(degrees, [0])\n",
        "  D = D.power(-1)\n",
        "  mx = mx.dot(D)\n",
        "  return mx\n",
        "\n",
        "\n",
        "def scattering1st(spmx,order):\n",
        "\n",
        "  I_n = sp.eye(spmx.shape[0])\n",
        "  adj_sct = 0.5*(spmx+I_n) # P = 1/2 * (I + WD^-1)\n",
        "  adj_power = adj_sct\n",
        "  adj_power = sparse_mx_to_torch_sparse_tensor(adj_power).cuda()\n",
        "  adj_sct = sparse_mx_to_torch_sparse_tensor(adj_sct).cuda()\n",
        "  I_n = sparse_mx_to_torch_sparse_tensor(I_n)\n",
        "  if order>1:\n",
        "    for i in range(order-1):\n",
        "      # Generating P^(2^(k-1))\n",
        "      adj_power = torch.spmm(adj_power,adj_sct.to_dense())\n",
        "      print('Generating SCT')\n",
        "    # Generating. final scattering of order K -> (I - P^(2^(k-1))) * P^(2^(k-1))\n",
        "    adj_int = torch.spmm((adj_power-I_n.cuda()),adj_power)\n",
        "  else:\n",
        "    # Generating. final scattering of order K -> (I - P^(2^(k-1))) * P^(2^(k-1))\n",
        "    adj_int = torch.spmm((adj_power-I_n.cuda()),adj_power.to_dense())\n",
        "  return adj_int\n",
        "\n",
        "\n",
        "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
        "  \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
        "  sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
        "  indices = torch.from_numpy(np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
        "  values = torch.from_numpy(sparse_mx.data)\n",
        "  shape = torch.Size(sparse_mx.shape)\n",
        "  return torch.sparse.FloatTensor(indices, values, shape)\n",
        "\n",
        "\n",
        "def parse_index_file(filename):\n",
        "  #Parse index file.\n",
        "  index = []\n",
        "  for line in open(filename):\n",
        "      index.append(int(line.strip()))\n",
        "  return index\n",
        "\n",
        "def accuracy(output, labels):\n",
        "  preds = output.max(1)[1].type_as(labels)\n",
        "  correct = preds.eq(labels).double()\n",
        "  correct = correct.sum()\n",
        "  return correct / len(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzVGh8eiTWQA"
      },
      "source": [
        "def load_citation(dataset_str=\"citeseer\", normalization=\"AugNormAdj\", cuda=True):\n",
        "  \"\"\"  \n",
        "  Load Citation Networks Datasets.\n",
        "  \"\"\"\n",
        "  names = ['x', 'y', 'tx', 'ty', 'allx', 'ally', 'graph']\n",
        "  objects = []\n",
        "  for i in range(len(names)):\n",
        "    with open(\"/content/drive/MyDrive/THESIS/Databases/data/ind.{}.{}\".format(dataset_str.lower(), names[i]), 'rb') as f:\n",
        "      if sys.version_info > (3, 0):\n",
        "          objects.append(pkl.load(f, encoding='latin1'))\n",
        "      else:\n",
        "          objects.append(pkl.load(f))\n",
        "\n",
        "  x, y, tx, ty, allx, ally, graph = tuple(objects)\n",
        "  test_idx_reorder = parse_index_file(\"/content/drive/MyDrive/THESIS/Databases/data/ind.{}.test.index\".format(dataset_str))\n",
        "  test_idx_range = np.sort(test_idx_reorder)\n",
        "  if dataset_str == 'citeseer':\n",
        "    # Fix citeseer dataset (there are some isolated nodes in the graph)\n",
        "    # Find isolated nodes, add them as zero-vecs into the right position\n",
        "    test_idx_range_full = range(min(test_idx_reorder), max(test_idx_reorder)+1)\n",
        "    tx_extended = sp.lil_matrix((len(test_idx_range_full), x.shape[1]))\n",
        "    tx_extended[test_idx_range-min(test_idx_range), :] = tx\n",
        "    tx = tx_extended\n",
        "    ty_extended = np.zeros((len(test_idx_range_full), y.shape[1]))\n",
        "    ty_extended[test_idx_range-min(test_idx_range), :] = ty\n",
        "    ty = ty_extended\n",
        "\n",
        "  features = sp.vstack((allx, tx)).tolil()\n",
        "  features[test_idx_reorder, :] = features[test_idx_range, :]\n",
        "  adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph))\n",
        "  adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
        "  labels = np.vstack((ally, ty))\n",
        "  labels[test_idx_reorder, :] = labels[test_idx_range, :]\n",
        "\n",
        "\n",
        "  idx_test = test_idx_range.tolist()\n",
        "  idx_train = range(len(y))\n",
        "  idx_val = range(len(y), len(y)+500)\n",
        "\n",
        "  #   take from https://github.com/tkipf/pygcn/blob/master/pygcn/utils.py\n",
        "  #    idx_train = range(140)\n",
        "  #    idx_val = range(200, 500)\n",
        "  #    idx_test = range(500, 1500)\n",
        "\n",
        "\n",
        "  labels = torch.LongTensor(labels)\n",
        "  labels = torch.max(labels, dim=1)[1]\n",
        "  idx_train = torch.LongTensor(idx_train)\n",
        "  idx_val = torch.LongTensor(idx_val)\n",
        "  idx_test = torch.LongTensor(idx_test)\n",
        "\n",
        "  features = normalize(features)\n",
        "  A_tilde = normalize_adjacency_matrix(adj,sp.eye(adj.shape[0]))\n",
        "  adj = normalizemx(adj)\n",
        "  \n",
        "  print('Loading')\n",
        "  #adj_sct1 = scattering1st(adj,1) ## psi_1 = P(I-P)\n",
        "  #adj_sct2 = scattering1st(adj,2) # psi_2 = P^2(I-P^2)\n",
        "  #adj_sct4 = scattering1st(adj,4) # psi_3 = P^4(I-P^4)\n",
        "  adj = sparse_mx_to_torch_sparse_tensor(adj)\n",
        "  A_tilde = sparse_mx_to_torch_sparse_tensor(A_tilde)\n",
        "  features = torch.FloatTensor(np.array(features.todense()))\n",
        "  return features, adj, A_tilde, labels, idx_train, idx_val, idx_test\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_QCd14ATX5x",
        "outputId": "5613d4eb-e9f7-4180-f616-71804fd793ce"
      },
      "source": [
        "features, adj,A_tilde, labels, idx_train, idx_val, idx_test = load_citation()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: RuntimeWarning: divide by zero encountered in power\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Chi96sFsTuZr"
      },
      "source": [
        "# MODELS\n",
        "\n",
        "First the convolutional structure is defined to finally being called in a nn Module. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_H3_mkjDTh9o"
      },
      "source": [
        "class MLP(Module):\n",
        "    \"\"\"\n",
        "    A Simple two layers MLP to make SGC a bit better.\n",
        "    \"\"\"\n",
        "    def __init__(self, nfeat, nhid, nclass, dp=0.2):\n",
        "        super(MLP, self).__init__()\n",
        "        self.W1 = nn.Linear(nfeat, nhid)\n",
        "        self.W2 = nn.Linear(nhid, nclass)\n",
        "        self.dp = dp\n",
        "        self.act = nn.PReLU()\n",
        "        self.num_class = nclass\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act(self.W1(x))\n",
        "        x = nn.Dropout(p=self.dp)(x)\n",
        "        return self.W2(x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLi7rZaGTwlr"
      },
      "source": [
        "epochs = 200\n",
        "lr = 0.01\n",
        "cuda = torch.cuda.is_available()\n",
        "hidden_channels=16\n",
        "fastmode = False\n",
        "\n",
        "\"\"\"if cuda:\n",
        "    model = model.cuda()\n",
        "    features = features.cuda()\n",
        "    #adj = adj.cuda()\n",
        "    #A_tilde = A_tilde.cuda()\n",
        "    labels = labels.cuda()\n",
        "    idx_train = idx_train.cuda()\n",
        "    idx_val = idx_val.cuda()\n",
        "    idx_test = idx_test.cuda()\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "model = MLP(features.shape[1], hidden_channels, labels.max().item() + 1)\n",
        "optimizer = optim.Adam(model.parameters(),lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scheduler = StepLR(optimizer, step_size=50, gamma=0.9)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umu76QY_UlZR"
      },
      "source": [
        "from torch.utils import data\n",
        "class FeaturesData(data.Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    self.labels = y\n",
        "    self.features = X\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.features)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    # Select sample\n",
        "    X = self.features[index]\n",
        "    y = self.labels[index]\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def get_data_loaders(X_train, y_train, X_val, y_val):\n",
        "\n",
        "  train_set = FeaturesData(X_train, y_train)\n",
        "  val_set = FeaturesData(X_val, y_val)\n",
        "  trainLoader = data.DataLoader(dataset=train_set, batch_size=X_train.shape[1], shuffle=True)\n",
        "  valLoader = data.DataLoader(dataset=val_set, batch_size=X_train.shape[1], shuffle=False)\n",
        "  return trainLoader, valLoader\n",
        "\n",
        "trainLoader, valLoader = get_data_loaders(features[idx_train], labels[idx_train], features[idx_val], labels[idx_val])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDIzB0oeWXm1"
      },
      "source": [
        "from time import perf_counter\n",
        "\n",
        "def train(verbose=True, patience=800):\n",
        "  best = 0\n",
        "  best_ep = 0\n",
        "  wait = 0\n",
        "  t = perf_counter()\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    train_correct = 0\n",
        "    for x, y in trainLoader:\n",
        "      model.train()\n",
        "      optimizer.zero_grad()\n",
        "      output = model(x)\n",
        "      loss_train = criterion(output, y)\n",
        "      loss_train.backward()\n",
        "      optimizer.step()\n",
        "      train_correct += output.argmax(1).eq(y).double().sum()\n",
        "    # Early stopping\n",
        "    with torch.no_grad():\n",
        "      model.eval()\n",
        "      corrects = 0\n",
        "      for x, y in valLoader:\n",
        "        output = model(x)\n",
        "        loss_val = criterion(output, y)\n",
        "        corrects += output.argmax(1).eq(y).double().sum()\n",
        "      acc_val = corrects.item() / labels[idx_val].size(-1)\n",
        "    if acc_val > best:\n",
        "      if verbose:\n",
        "        print(\"Epoch\\t{} - Val acc: {:.4f}\".format(epoch, acc_val))\n",
        "      best = acc_val\n",
        "      best_ep = epoch\n",
        "      wait = 0\n",
        "      torch.save(model.state_dict(), \"best_gfnn.pkl\")\n",
        "    else:\n",
        "      wait+=1\n",
        "    if wait == patience:\n",
        "      print(\"Early stopping at epoch {}\".format(epoch))\n",
        "      break\n",
        "  train_time = perf_counter()-t\n",
        "  with torch.no_grad():\n",
        "    print(\"Loading at epoch {}\".format(best_ep))\n",
        "    model.load_state_dict(torch.load('best_gfnn.pkl'))\n",
        "    model.eval()\n",
        "    for x, y in valLoader:\n",
        "      output = model(x)\n",
        "      loss_val = criterion(output, y)\n",
        "      corrects = output.argmax(1).eq(y).double().sum()\n",
        "  acc_val = corrects.item() / labels[idx_val].size(-1)\n",
        "  acc_train = train_correct.item() / labels[idx_train].size(-1)\n",
        "  \n",
        "\n",
        "  return model, acc_val, train_time\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwA415-MZXeR",
        "outputId": "279c5932-a07c-4e3f-e659-bc9b98d007e9"
      },
      "source": [
        "acc_validation= []\n",
        "training_time= []\n",
        "for i in range(5):\n",
        "  model, acc_val, train_time = train()\n",
        "  acc_validation.append(acc_val)\n",
        "  training_time.append(train_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch\t0 - Val acc: 0.2240\n",
            "Epoch\t1 - Val acc: 0.2260\n",
            "Epoch\t2 - Val acc: 0.2320\n",
            "Epoch\t5 - Val acc: 0.2480\n",
            "Epoch\t6 - Val acc: 0.2740\n",
            "Epoch\t7 - Val acc: 0.2780\n",
            "Epoch\t18 - Val acc: 0.3080\n",
            "Epoch\t19 - Val acc: 0.3100\n",
            "Epoch\t20 - Val acc: 0.3360\n",
            "Epoch\t22 - Val acc: 0.3420\n",
            "Epoch\t24 - Val acc: 0.3780\n",
            "Epoch\t27 - Val acc: 0.3820\n",
            "Epoch\t29 - Val acc: 0.4180\n",
            "Epoch\t35 - Val acc: 0.4320\n",
            "Epoch\t55 - Val acc: 0.4340\n",
            "Epoch\t58 - Val acc: 0.4440\n",
            "Epoch\t64 - Val acc: 0.4460\n",
            "Epoch\t70 - Val acc: 0.4560\n",
            "Epoch\t72 - Val acc: 0.4620\n",
            "Epoch\t74 - Val acc: 0.4700\n",
            "Epoch\t79 - Val acc: 0.4780\n",
            "Epoch\t89 - Val acc: 0.4940\n",
            "Epoch\t108 - Val acc: 0.4960\n",
            "Epoch\t160 - Val acc: 0.5020\n",
            "Epoch\t168 - Val acc: 0.5100\n",
            "Loading at epoch 168\n",
            "Epoch\t0 - Val acc: 0.4720\n",
            "Epoch\t1 - Val acc: 0.4820\n",
            "Epoch\t3 - Val acc: 0.4860\n",
            "Epoch\t5 - Val acc: 0.4900\n",
            "Epoch\t9 - Val acc: 0.4960\n",
            "Epoch\t14 - Val acc: 0.4980\n",
            "Epoch\t42 - Val acc: 0.5000\n",
            "Epoch\t46 - Val acc: 0.5060\n",
            "Epoch\t56 - Val acc: 0.5120\n",
            "Loading at epoch 56\n",
            "Epoch\t0 - Val acc: 0.4860\n",
            "Epoch\t1 - Val acc: 0.4900\n",
            "Epoch\t13 - Val acc: 0.5000\n",
            "Epoch\t102 - Val acc: 0.5120\n",
            "Loading at epoch 102\n",
            "Epoch\t0 - Val acc: 0.4740\n",
            "Epoch\t2 - Val acc: 0.4840\n",
            "Epoch\t3 - Val acc: 0.4900\n",
            "Epoch\t11 - Val acc: 0.5020\n",
            "Loading at epoch 11\n",
            "Epoch\t0 - Val acc: 0.4820\n",
            "Epoch\t1 - Val acc: 0.4940\n",
            "Epoch\t28 - Val acc: 0.4980\n",
            "Epoch\t39 - Val acc: 0.5000\n",
            "Epoch\t94 - Val acc: 0.5080\n",
            "Loading at epoch 94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZC6MF8hbHk6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d5ba2a7-d2f2-4395-d16e-c4f9f76d2943"
      },
      "source": [
        "total_val_accuracy = np.mean(acc_validation)\n",
        "total_training_time = np.mean(training_time)\n",
        "print('total accuracy', total_val_accuracy)\n",
        "print('total training time', total_training_time)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total accuracy 0.48040000000000005\n",
            "total training time 3.970145989000014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALGpiR5_snVz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}