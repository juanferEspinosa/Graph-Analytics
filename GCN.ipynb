{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GCN 81%.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNV45nwoITKndD0fpO7ZYMa"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORTS"
      ],
      "metadata": {
        "id": "xfCKxzfZT__a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZK8Q3YOOgzm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parameter import Parameter\n",
        "import torch.nn as nn\n",
        "from torch.nn.modules.module import Module\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import MultiStepLR,StepLR\n",
        "\n",
        "import numpy as np\n",
        "import pickle as pkl\n",
        "import networkx as nx\n",
        "import scipy.sparse as sp\n",
        "from scipy.sparse.linalg.eigen.arpack import eigsh\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6P67xGh_QEH0",
        "outputId": "8da46a3b-28ee-401d-a56f-703d1713a7ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import  argparse\n",
        "\n",
        "args = argparse.ArgumentParser()\n",
        "args.add_argument('--dataset', default='cora')\n",
        "args.add_argument('--model', default='gcn')\n",
        "args.add_argument('--learning_rate', type=float, default=0.01)\n",
        "args.add_argument('--epochs', type=int, default=400)\n",
        "args.add_argument('--hidden', type=int, default=16)\n",
        "args.add_argument('--dropout', type=float, default=0.5)\n",
        "args.add_argument('--weight_decay', type=float, default=5e-4)\n",
        "args.add_argument('--early_stopping', type=int, default=10)\n",
        "args.add_argument('--max_degree', type=int, default=3)\n",
        "args.add_argument('-f')\n",
        "\n",
        "args = args.parse_args()"
      ],
      "metadata": {
        "id": "dL9IKvdUVCiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATASET"
      ],
      "metadata": {
        "id": "Y3YnmzjFUCgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sparse_to_tuple(sparse_mx):\n",
        "  \"\"\"\n",
        "  Convert sparse matrix to tuple representation.\n",
        "  \"\"\"\n",
        "  def to_tuple(mx):\n",
        "      if not sp.isspmatrix_coo(mx):\n",
        "          mx = mx.tocoo()\n",
        "      coords = np.vstack((mx.row, mx.col)).transpose()\n",
        "      values = mx.data\n",
        "      shape = mx.shape\n",
        "      return coords, values, shape\n",
        "\n",
        "  if isinstance(sparse_mx, list):\n",
        "      for i in range(len(sparse_mx)):\n",
        "          sparse_mx[i] = to_tuple(sparse_mx[i])\n",
        "  else:\n",
        "      sparse_mx = to_tuple(sparse_mx)\n",
        "\n",
        "  return sparse_mx\n",
        "\n",
        "\n",
        "def preprocess_features(features):\n",
        "  \"\"\"\n",
        "  Row-normalize feature matrix and convert to tuple representation\n",
        "  \"\"\"\n",
        "  rowsum = np.array(features.sum(1)) # get sum of each row, [2708, 1]\n",
        "  r_inv = np.power(rowsum, -1).flatten() # 1/rowsum, [2708]\n",
        "  r_inv[np.isinf(r_inv)] = 0. # zero inf data\n",
        "  r_mat_inv = sp.diags(r_inv) # sparse diagonal matrix, [2708, 2708]\n",
        "  features = r_mat_inv.dot(features) # D^-1:[2708, 2708]@X:[2708, 2708]\n",
        "  return sparse_to_tuple(features) # [coordinates, data, shape], []\n",
        "\n",
        "\n",
        "def normalize_adj(adj):\n",
        "  \"\"\"Symmetrically normalize adjacency matrix.\"\"\"\n",
        "  adj = sp.coo_matrix(adj)\n",
        "  rowsum = np.array(adj.sum(1)) # D\n",
        "  d_inv_sqrt = np.power(rowsum, -0.5).flatten() # D^-0.5\n",
        "  d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
        "  d_mat_inv_sqrt = sp.diags(d_inv_sqrt) # D^-0.5\n",
        "  return adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo() # D^-0.5AD^0.5\n",
        "\n",
        "\n",
        "def preprocess_adj(adj):\n",
        "  \"\"\"Preprocessing of adjacency matrix for simple GCN model and conversion to tuple representation.\"\"\"\n",
        "  adj_normalized = normalize_adj(adj + sp.eye(adj.shape[0]))\n",
        "  return sparse_to_tuple(adj_normalized)\n",
        "\n",
        "def sparse_dropout(x, rate, noise_shape):\n",
        "  \"\"\"\n",
        "  :param x:\n",
        "  :param rate:\n",
        "  :param noise_shape: int scalar\n",
        "  :return:\n",
        "  \"\"\"\n",
        "  random_tensor = 1 - rate\n",
        "  random_tensor += torch.rand(noise_shape).to(x.device)\n",
        "  dropout_mask = torch.floor(random_tensor).byte()\n",
        "  i = x._indices() # [2, 49216]\n",
        "  v = x._values() # [49216]\n",
        "\n",
        "  # [2, 4926] => [49216, 2] => [remained node, 2] => [2, remained node]\n",
        "  i = i[:, dropout_mask]\n",
        "  v = v[dropout_mask]\n",
        "\n",
        "  out = torch.sparse.FloatTensor(i, v, x.shape).to(x.device)\n",
        "\n",
        "  out = out * (1./ (1-rate))\n",
        "\n",
        "  return out\n",
        "\n",
        "def masked_loss(out, label, mask):\n",
        "\n",
        "  loss = F.cross_entropy(out, label, reduction='none')\n",
        "  mask = mask.float()\n",
        "  mask = mask / mask.mean()\n",
        "  loss *= mask\n",
        "  loss = loss.mean()\n",
        "  return loss\n",
        "\n",
        "\n",
        "def masked_acc(out, label, mask):\n",
        "  # [node, f]\n",
        "  pred = out.argmax(dim=1)\n",
        "  correct = torch.eq(pred, label).float()\n",
        "  mask = mask.float()\n",
        "  mask = mask / mask.mean()\n",
        "  correct *= mask\n",
        "  acc = correct.mean()\n",
        "  return acc"
      ],
      "metadata": {
        "id": "uiVQS7IsQdDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_index_file(filename):\n",
        "  \"\"\"\n",
        "  Parse index file.\n",
        "  \"\"\"\n",
        "  index = []\n",
        "  for line in open(filename):\n",
        "      index.append(int(line.strip()))\n",
        "  return index\n",
        "\n",
        "def sample_mask(idx, l):\n",
        "  \"\"\"\n",
        "  Create mask.\n",
        "  \"\"\"\n",
        "  mask = np.zeros(l)\n",
        "  mask[idx] = 1\n",
        "  return np.array(mask, dtype=np.bool)\n",
        "\n",
        "def load_data(dataset_str):\n",
        "  \"\"\"\n",
        "  Loads input data from gcn/data directory\n",
        "  ind.dataset_str.x => the feature vectors of the training instances as scipy.sparse.csr.csr_matrix object;\n",
        "  ind.dataset_str.tx => the feature vectors of the test instances as scipy.sparse.csr.csr_matrix object;\n",
        "  ind.dataset_str.allx => the feature vectors of both labeled and unlabeled training instances\n",
        "      (a superset of ind.dataset_str.x) as scipy.sparse.csr.csr_matrix object;\n",
        "  ind.dataset_str.y => the one-hot labels of the labeled training instances as numpy.ndarray object;\n",
        "  ind.dataset_str.ty => the one-hot labels of the test instances as numpy.ndarray object;\n",
        "  ind.dataset_str.ally => the labels for instances in ind.dataset_str.allx as numpy.ndarray object;\n",
        "  ind.dataset_str.graph => a dict in the format {index: [index_of_neighbor_nodes]} as collections.defaultdict\n",
        "      object;\n",
        "  ind.dataset_str.test.index => the indices of test instances in graph, for the inductive setting as list object.\n",
        "  All objects above must be saved using python pickle module.\n",
        "  :param dataset_str: Dataset name\n",
        "  :return: All data input files loaded (as well the training/test data).\n",
        "  \"\"\"\n",
        "  names = ['x', 'y', 'tx', 'ty', 'allx', 'ally', 'graph']\n",
        "  objects = []\n",
        "  for i in range(len(names)):\n",
        "    with open(\"/content/drive/MyDrive/THESIS/Databases/data/ind.{}.{}\".format(dataset_str, names[i]), 'rb') as f:\n",
        "      if sys.version_info > (3, 0):\n",
        "        objects.append(pkl.load(f, encoding='latin1'))\n",
        "      else:\n",
        "        objects.append(pkl.load(f))\n",
        "\n",
        "  x, y, tx, ty, allx, ally, graph = tuple(objects)\n",
        "  test_idx_reorder = parse_index_file(\"/content/drive/MyDrive/THESIS/Databases/data/ind.{}.test.index\".format(dataset_str))\n",
        "  test_idx_range = np.sort(test_idx_reorder)\n",
        "\n",
        "  if dataset_str == 'citeseer':\n",
        "    # Fix citeseer dataset (there are some isolated nodes in the graph)\n",
        "    # Find isolated nodes, add them as zero-vecs into the right position\n",
        "    test_idx_range_full = range(min(test_idx_reorder), max(test_idx_reorder)+1)\n",
        "    tx_extended = sp.lil_matrix((len(test_idx_range_full), x.shape[1]))\n",
        "    tx_extended[test_idx_range-min(test_idx_range), :] = tx\n",
        "    tx = tx_extended\n",
        "    ty_extended = np.zeros((len(test_idx_range_full), y.shape[1]))\n",
        "    ty_extended[test_idx_range-min(test_idx_range), :] = ty\n",
        "    ty = ty_extended\n",
        "\n",
        "  features = sp.vstack((allx, tx)).tolil()\n",
        "  features[test_idx_reorder, :] = features[test_idx_range, :]\n",
        "  adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph))\n",
        "\n",
        "  labels = np.vstack((ally, ty))\n",
        "  labels[test_idx_reorder, :] = labels[test_idx_range, :]\n",
        "\n",
        "  idx_test = test_idx_range.tolist()\n",
        "  idx_train = range(len(y))\n",
        "  idx_val = range(len(y), len(y)+500)\n",
        "\n",
        "  train_mask = sample_mask(idx_train, labels.shape[0])\n",
        "  val_mask = sample_mask(idx_val, labels.shape[0])\n",
        "  test_mask = sample_mask(idx_test, labels.shape[0])\n",
        "\n",
        "  y_train = np.zeros(labels.shape)\n",
        "  y_val = np.zeros(labels.shape)\n",
        "  y_test = np.zeros(labels.shape)\n",
        "  y_train[train_mask, :] = labels[train_mask, :]\n",
        "  y_val[val_mask, :] = labels[val_mask, :]\n",
        "  y_test[test_mask, :] = labels[test_mask, :]\n",
        "\n",
        "  return adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask"
      ],
      "metadata": {
        "id": "adj4dOPmOyJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask = load_data(args.dataset)"
      ],
      "metadata": {
        "id": "1-48iN5BPp7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = preprocess_features(features) # [coordinates, data, shape]\n",
        "A_hats = preprocess_adj(adj)"
      ],
      "metadata": {
        "id": "EY2uuI8_QAcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# should send all the info to cuda\n",
        "train_label = torch.from_numpy(y_train).long()\n",
        "num_classes = train_label.shape[1]\n",
        "train_label = train_label.argmax(dim=1)\n",
        "train_mask = torch.from_numpy(train_mask.astype(np.int))\n",
        "val_label = torch.from_numpy(y_val).long()\n",
        "val_label = val_label.argmax(dim=1)\n",
        "val_mask = torch.from_numpy(val_mask.astype(np.int))\n",
        "test_label = torch.from_numpy(y_test).long()\n",
        "test_label = test_label.argmax(dim=1)\n",
        "test_mask = torch.from_numpy(test_mask.astype(np.int))"
      ],
      "metadata": {
        "id": "Tnx-TbDtQmaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = torch.from_numpy(features[0]).long()\n",
        "v = torch.from_numpy(features[1])\n",
        "feature = torch.sparse.FloatTensor(i.t(), v, features[2])\n",
        "\n",
        "i = torch.from_numpy(A_hats[0]).long()\n",
        "v = torch.from_numpy(A_hats[1])\n",
        "A_hat = torch.sparse.FloatTensor(i.t(), v, A_hats[2]).float()"
      ],
      "metadata": {
        "id": "zVL1pwueQ_jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_features_nonzero = feature._nnz()\n",
        "feat_dim = feature.shape[1]"
      ],
      "metadata": {
        "id": "OPSuGWgVTC7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODELS"
      ],
      "metadata": {
        "id": "qiwb8hKBUFAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphConvolution(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim, output_dim, num_features_nonzero, dropout=0., is_sparse_inputs=False, bias=False, activation = F.relu):\n",
        "    super(GraphConvolution, self).__init__()\n",
        "\n",
        "\n",
        "    self.dropout = dropout\n",
        "    self.bias = bias\n",
        "    self.activation = activation\n",
        "    self.is_sparse_inputs = is_sparse_inputs\n",
        "    self.num_features_nonzero = num_features_nonzero\n",
        "\n",
        "    self.weight = nn.Parameter(torch.randn(input_dim, output_dim))\n",
        "    self.bias = None\n",
        "    if bias:\n",
        "      self.bias = nn.Parameter(torch.zeros(output_dim))\n",
        "    \n",
        "  def forward(self, inputs):\n",
        "    x, adj = inputs\n",
        "    if self.training and self.is_sparse_inputs:\n",
        "      x = sparse_dropout(x, self.dropout, self.num_features_nonzero)\n",
        "\n",
        "    if self.is_sparse_inputs:\n",
        "      xw = torch.sparse.mm(x, self.weight)\n",
        "    else:\n",
        "      xw = torch.mm(x, self.weight)\n",
        "    out = torch.sparse.mm(adj, xw)\n",
        "\n",
        "    if self.bias is not None:\n",
        "      out += self.bias\n",
        "\n",
        "    return self.activation(out), adj\n"
      ],
      "metadata": {
        "id": "hlH1SCC0WGlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim, output_dim, num_features_nonzero):\n",
        "    super(GCN, self).__init__()\n",
        "\n",
        "    self.input_dim = input_dim # 1433\n",
        "    self.output_dim = output_dim\n",
        "\n",
        "    print('input dim:', input_dim)\n",
        "    print('output dim:', output_dim)\n",
        "    print('num_features_nonzero:', num_features_nonzero)\n",
        "\n",
        "    self.layers = nn.Sequential(GraphConvolution(input_dim, args.hidden, num_features_nonzero,\n",
        "                                                     activation=F.relu,\n",
        "                                                     dropout=args.dropout,\n",
        "                                                     is_sparse_inputs=True),\n",
        "\n",
        "                                GraphConvolution(args.hidden, output_dim, num_features_nonzero,\n",
        "                                                     activation=F.relu,\n",
        "                                                     dropout=args.dropout,\n",
        "                                                     is_sparse_inputs=False),\n",
        "\n",
        "                             )\n",
        "  def forward(self, inputs):\n",
        "\n",
        "    x, adj = inputs\n",
        "\n",
        "    x = self.layers((x, adj))\n",
        "    return x\n",
        "  \n",
        "  def l2_loss(self): \n",
        "    layer = self.layers.children() \n",
        "    layer = next(iter(layer)) \n",
        "    loss = None \n",
        "    for layer in self.layers: \n",
        "      for p in layer.parameters(): \n",
        "        if loss is None: \n",
        "          loss = p.pow(2).sum() \n",
        "        else: \n",
        "          loss += p.pow(2).sum() \n",
        "    return loss\n",
        "  "
      ],
      "metadata": {
        "id": "TceG4SWpTM3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = GCN(feat_dim, num_classes, num_features_nonzero)\n",
        "optimizer = optim.Adam(net.parameters(), lr=args.learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8m0FanAzV4Qe",
        "outputId": "55c5b0ad-9043-487d-946b-56cde3d50cae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input dim: 1433\n",
            "output dim: 7\n",
            "num_features_nonzero: 49216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net.train()\n",
        "for epoch in range(args.epochs):\n",
        "  out = net((feature, A_hat))\n",
        "  out = out[0]\n",
        "\n",
        "  loss = masked_loss(out, train_label, train_mask)\n",
        "  loss += args.weight_decay * net.l2_loss()\n",
        "\n",
        "  acc = masked_acc(out, train_label, train_mask)\n",
        "  acc_val = masked_acc(out, val_label, val_mask)\n",
        "  acc_test = masked_acc(out, test_label, test_mask)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "\n",
        "    print(epoch, loss.item(), acc.item(), acc_val.item(), acc_test.item())\n",
        "\n",
        "net.eval()\n",
        "\n",
        "out = net((feature, A_hat))\n",
        "out = out[0]\n",
        "acc = masked_acc(out, test_label, test_mask)\n",
        "print('test:', acc.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZEjUkPSZKgi",
        "outputId": "d678b28e-f571-4e5b-a97b-e164498404a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 13.632501602172852 0.12142856419086456 0.12600000202655792 0.13199999928474426\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:63: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:30.)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:64: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:30.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 11.910115242004395 0.12857143580913544 0.14000000059604645 0.1459999829530716\n",
            "20 10.37842082977295 0.19999998807907104 0.18999998271465302 0.1810000091791153\n",
            "30 9.081487655639648 0.25 0.19999998807907104 0.21799999475479126\n",
            "40 7.981378555297852 0.30714282393455505 0.21199999749660492 0.2369999885559082\n",
            "50 7.042667865753174 0.3999999761581421 0.2459999918937683 0.2619999945163727\n",
            "60 6.218443870544434 0.4642857015132904 0.27399998903274536 0.2959999740123749\n",
            "70 5.512348175048828 0.5071429014205933 0.2879999876022339 0.3190000057220459\n",
            "80 4.915709495544434 0.550000011920929 0.37999996542930603 0.38599997758865356\n",
            "90 4.3901262283325195 0.7000000476837158 0.42799997329711914 0.44699999690055847\n",
            "100 3.8890771865844727 0.7500000596046448 0.4819999933242798 0.4899999797344208\n",
            "110 3.469174861907959 0.7571429014205933 0.5080000162124634 0.5210000872612\n",
            "120 3.0877814292907715 0.8071427941322327 0.5579999685287476 0.5679999589920044\n",
            "130 2.7454276084899902 0.8571428656578064 0.5759999752044678 0.5759999752044678\n",
            "140 2.4802980422973633 0.9071428179740906 0.6079999804496765 0.6340000033378601\n",
            "150 2.2389323711395264 0.9285714626312256 0.6859999895095825 0.7009999752044678\n",
            "160 2.040842056274414 0.9571428894996643 0.7200000286102295 0.7259999513626099\n",
            "170 1.8761299848556519 0.9357143044471741 0.7279999256134033 0.7669999599456787\n",
            "180 1.7069247961044312 0.9571428894996643 0.7399999499320984 0.7589999437332153\n",
            "190 1.5876057147979736 0.9714285135269165 0.7560000419616699 0.7559999823570251\n",
            "200 1.4731450080871582 0.964285671710968 0.7460000514984131 0.7709999680519104\n",
            "210 1.4074689149856567 0.9928571581840515 0.7619999647140503 0.7799999713897705\n",
            "220 1.320296287536621 0.964285671710968 0.7399999499320984 0.781000018119812\n",
            "230 1.2467975616455078 0.978571355342865 0.7679999470710754 0.7929999232292175\n",
            "240 1.1807868480682373 0.978571355342865 0.7580000162124634 0.7689999938011169\n",
            "250 1.1480088233947754 0.9571428894996643 0.7339999675750732 0.7549999952316284\n",
            "260 1.1187140941619873 0.9928571581840515 0.793999969959259 0.7890000343322754\n",
            "270 1.0601153373718262 0.9785714149475098 0.7620000243186951 0.7619999647140503\n",
            "280 1.0626299381256104 0.964285671710968 0.7839999198913574 0.7929999232292175\n",
            "290 1.0047006607055664 0.9857143759727478 0.7540000081062317 0.7689999938011169\n",
            "300 1.0093741416931152 0.9857142567634583 0.7479999661445618 0.7900000214576721\n",
            "310 1.0120855569839478 0.9928571581840515 0.768000066280365 0.7870000004768372\n",
            "320 0.9513969421386719 0.9928571581840515 0.7559999823570251 0.7880000472068787\n",
            "330 0.9719698429107666 0.9785715341567993 0.7699999809265137 0.7829999923706055\n",
            "340 0.9495700597763062 0.9785714149475098 0.7580000162124634 0.777999997138977\n",
            "350 0.9525597095489502 0.9857143759727478 0.7699999809265137 0.7899999618530273\n",
            "360 0.9479830265045166 0.9857143759727478 0.7619999647140503 0.7990000247955322\n",
            "370 0.9426133632659912 0.978571355342865 0.7819998860359192 0.7839999794960022\n",
            "380 0.893668532371521 0.9857143759727478 0.7580000162124634 0.778999924659729\n",
            "390 0.9227395057678223 0.978571355342865 0.7600000500679016 0.7829999923706055\n",
            "test: 0.8199999928474426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "y3F1b4uXefai"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}